# Real-Time Object Detection and Inference Pipeline (YOLOv8) on AWS/GCP

Train and deploy a real-time object detection API using YOLOv8 and serve it using Flask (locally) or on AWS/GCP cloud. Optionally, connect a simple web UI.

## ğŸ“¦ Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ yolo_infer.py          # Inference and visualization
â”‚   â”œâ”€â”€ train.py               # Training script (for custom data)
â”‚   â””â”€â”€ api.py                 # REST API (Flask)
â”œâ”€â”€ webapp/                    # (Optional) Simple frontend
â”œâ”€â”€ data/                      # Place images/videos here
â”œâ”€â”€ results/                   # Output images, logs
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## ğŸ Getting Started

1. Install dependencies:
   ```
   pip install -r requirements.txt
   ```
2. Run local inference:
   ```
   python src/yolo_infer.py --image data/sample.jpg
   ```
3. Start API server:
   ```
   python src/api.py
   ```
4. (Optional) Deploy to AWS/GCPâ€”see deployment instructions in repo.

## ğŸ”¬ Recommended Datasets

- [COCO](https://cocodataset.org/) (Standard benchmark)
- [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/)
- Use Ultralytics YOLOv8 pretrained models for demo

## ğŸŒ API

- POST `/predict` with image file, returns bounding boxes and class labels

---
